{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/anton/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import os.path\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEED_TRAIN = False\n",
    "FI_FILENAME = 'fin.txt'\n",
    "EPOCHS = 30\n",
    "FILENAME = \"model.09_oct_19\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, mode='rt', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_content(content):\n",
    "    lines = content.strip().split('\\n')\n",
    "    lines = [list(reversed(i.split('\\t'))) for i in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_en = array(parse_content(read_file(FI_FILENAME)))[:55000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Mene.', 'Go.'],\n",
       "       ['Moro!', 'Hi.'],\n",
       "       ['Terve.', 'Hi.'],\n",
       "       ...,\n",
       "       ['Suuri mullistus on tapahtunut teknologiassa.',\n",
       "        'A great revolution has taken place in technology.'],\n",
       "       ['Ryhmä ulkomaalaisia saapui Edoon, toisin sanoen Tokioon.',\n",
       "        'A group of foreigners arrived in Edo, i.e. Tokyo.'],\n",
       "       ['Tom niminen tyyppi etsi sinua tänä aamuna.',\n",
       "        'A guy named Tom was looking for you this morning.']],\n",
       "      dtype='<U345')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(dataset):\n",
    "    dataset[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in dataset[:,0]]\n",
    "    dataset[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in dataset[:,1]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower_case(dataset):\n",
    "    for i in range(len(dataset)): \n",
    "        dataset[i,0] = dataset[i,0].lower() \n",
    "        dataset[i,1] = dataset[i,1].lower()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(dataset):\n",
    "    without_punctuations = remove_punctuations(dataset)\n",
    "    return to_lower_case(without_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['mene', 'go'],\n",
       "       ['moro', 'hi'],\n",
       "       ['terve', 'hi'],\n",
       "       ...,\n",
       "       ['suuri mullistus on tapahtunut teknologiassa',\n",
       "        'a great revolution has taken place in technology'],\n",
       "       ['ryhmä ulkomaalaisia saapui edoon toisin sanoen tokioon',\n",
       "        'a group of foreigners arrived in edo ie tokyo'],\n",
       "       ['tom niminen tyyppi etsi sinua tänä aamuna',\n",
       "        'a guy named tom was looking for you this morning']],\n",
       "      dtype='<U345')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_fi_en = pre_process(fi_en)\n",
    "processed_fi_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['go', 'hi', 'hi', ...,\n",
       "       'a great revolution has taken place in technology',\n",
       "       'a group of foreigners arrived in edo ie tokyo',\n",
       "       'a guy named tom was looking for you this morning'], dtype='<U345')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sentences = processed_fi_en[:,1]\n",
    "en_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mene', 'moro', 'terve', ...,\n",
       "       'suuri mullistus on tapahtunut teknologiassa',\n",
       "       'ryhmä ulkomaalaisia saapui edoon toisin sanoen tokioon',\n",
       "       'tom niminen tyyppi etsi sinua tänä aamuna'], dtype='<U345')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_sentences = processed_fi_en[:,0]\n",
    "fi_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the lists with sentence lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(sentence):\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_l = [len(get_words(i)) for i in en_sentences]\n",
    "fi_l = [len(get_words(i)) for i in fi_sentences]\n",
    "        \n",
    "length_df = pd.DataFrame({'en':en_l, 'fi':fi_l}) \n",
    "length_df.hist(bins = 30) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(lines): \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer = tokenization(en_sentences)\n",
    "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
    "en_length = max(en_l)\n",
    "en_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_tokenizer = tokenization(fi_sentences)\n",
    "fi_vocab_size = len(fi_tokenizer.word_index) + 1\n",
    "fi_length = max(fi_l)\n",
    "fi_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):          \n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)      \n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')        \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FI - EN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['tomilla on ankara päänsärky', 'tom has a severe headache'],\n",
       "       ['onpa tänään kylmä', 'it sure is cold today'],\n",
       "       ['voisitko vastata puhelimeen', 'answer the telephone will you'],\n",
       "       ...,\n",
       "       ['minkäikäinen teidän siskonne on', 'how old is your sister'],\n",
       "       ['osaatko laskea kiinaksi kymmeneen',\n",
       "        'can you count to ten in chinese'],\n",
       "       ['he kuolivat taistelussa', 'they died in battle']], dtype='<U345')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(processed_fi_en, test_size=0.3, random_state= 12)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = encode_sequences(fi_tokenizer, fi_length, train[:, 0]) \n",
    "trainY = encode_sequences(en_tokenizer, en_length, train[:, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomilla on ankara päänsärky\n",
      "[  32    1 2242 5627    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train[:, 0][0])\n",
    "print(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom has a severe headache\n",
      "[   1   38    6 3428 1185    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train[:, 1][0])\n",
    "print(trainY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = encode_sequences(fi_tokenizer, fi_length, test[:, 0]) \n",
    "testY = encode_sequences(en_tokenizer, en_length, test[:, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olen ikuinen optimisti\n",
      "[   11 14739  4571     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(test[:, 0][0])\n",
    "print(testX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im always optimistic\n",
      "[ 20 160 777   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(test[:, 1][0])\n",
    "print(testY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NMT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(in_vocab,out_vocab, in_timesteps,out_timesteps,n):   \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, n, input_length=in_timesteps,mask_zero=True))\n",
    "    model.add(LSTM(n))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(n, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing model\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FILENAME):\n",
    "    print('loading existing model')\n",
    "    model = load_model(FILENAME)\n",
    "else:\n",
    "    model = build_model(fi_vocab_size, en_vocab_size, fi_length, en_length, 512)\n",
    "\n",
    "    rms = optimizers.RMSprop(lr=0.001) \n",
    "    model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NEED_TRAIN:\n",
    "    checkpoint = ModelCheckpoint(FILENAME, monitor='val_loss',  \n",
    "                             verbose=1, save_best_only=True, \n",
    "                             mode='min')\n",
    "    \n",
    "    history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "                    epochs=EPOCHS, batch_size=512, validation_split = 0.3, \n",
    "                    callbacks=[checkpoint], verbose=1)\n",
    "    \n",
    "    print(history)\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.legend(['train','validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):  \n",
    "    for word, index in tokenizer.word_index.items():                       \n",
    "        if index == n: \n",
    "            return word \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_tran(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, source_tokenizer, source_len, target_tokenizer):\n",
    "    sentence = pre_tran(sentence)\n",
    "    source = encode_sequences(source_tokenizer, source_len, array([sentence])) \n",
    "    p = model.predict_classes(source)[0]\n",
    "    temp = []\n",
    "    for j in range(len(p)):             \n",
    "        t = get_word(p[j], target_tokenizer)             \n",
    "        if j > 0:                 \n",
    "            if (t == get_word(p[j-1], target_tokenizer)) or (t == None):                       \n",
    "                 temp.append('')                 \n",
    "            else:                      \n",
    "                 temp.append(t)             \n",
    "        else:                    \n",
    "            if(t == None):                                   \n",
    "                 temp.append('')                    \n",
    "            else:                           \n",
    "                 temp.append(t)\n",
    "    return ' '.join(temp).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_fi_en(sentence):\n",
    "    return predict(sentence, fi_tokenizer, fi_length, en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call the doctor'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_fi_en('Soita lääkärille.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_fi_en('Hypätkää')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(testX.reshape((testX.shape[0], testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = [] \n",
    "for i in preds:        \n",
    "    temp = []        \n",
    "    for j in range(len(i)):             \n",
    "        t = get_word(i[j], en_tokenizer)             \n",
    "        if j > 0:                 \n",
    "            if (t==get_word(i[j-1],en_tokenizer))or(t== None):                       \n",
    "                 temp.append('')                 \n",
    "            else:                      \n",
    "                 temp.append(t)             \n",
    "        else:                    \n",
    "            if(t == None):                                   \n",
    "                 temp.append('')                    \n",
    "            else:                           \n",
    "                 temp.append(t)        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'source': test[:,0], 'actual' : test[:,1], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10717</th>\n",
       "      <td>hän on kiva</td>\n",
       "      <td>hes a kind person</td>\n",
       "      <td>he is kind person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15329</th>\n",
       "      <td>tomin vaatteet ovat epämuodikkaat</td>\n",
       "      <td>toms clothes are out of fashion</td>\n",
       "      <td>toms clothes are in of fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>menimme kävelylle metsään</td>\n",
       "      <td>we went for a walk in the forest</td>\n",
       "      <td>we went at a hotel a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>en tylsistytä sinua yksityiskohdilla</td>\n",
       "      <td>i wont bore you with the details</td>\n",
       "      <td>i dont think you with my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14746</th>\n",
       "      <td>jonnekin meidän pitää vetää raja</td>\n",
       "      <td>we have to draw a line somewhere</td>\n",
       "      <td>we need to improve a stamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>otin lainaksi tomin auton</td>\n",
       "      <td>i borrowed toms car</td>\n",
       "      <td>i bought my car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>pystyt pian hiihtämään hyvin</td>\n",
       "      <td>you will soon be able to ski well</td>\n",
       "      <td>i can see but fast well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>mene kotiin</td>\n",
       "      <td>please go home</td>\n",
       "      <td>go home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11671</th>\n",
       "      <td>ranskalaiset pitävät etanoista</td>\n",
       "      <td>the french like to eat snails</td>\n",
       "      <td>your french is to a pilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>minä löydän ne</td>\n",
       "      <td>ill find them</td>\n",
       "      <td>ill pay them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     source  \\\n",
       "10717                           hän on kiva   \n",
       "15329     tomin vaatteet ovat epämuodikkaat   \n",
       "7988              menimme kävelylle metsään   \n",
       "1726   en tylsistytä sinua yksityiskohdilla   \n",
       "14746      jonnekin meidän pitää vetää raja   \n",
       "6194              otin lainaksi tomin auton   \n",
       "2256           pystyt pian hiihtämään hyvin   \n",
       "10028                           mene kotiin   \n",
       "11671        ranskalaiset pitävät etanoista   \n",
       "370                          minä löydän ne   \n",
       "\n",
       "                                  actual  \\\n",
       "10717                  hes a kind person   \n",
       "15329    toms clothes are out of fashion   \n",
       "7988    we went for a walk in the forest   \n",
       "1726    i wont bore you with the details   \n",
       "14746   we have to draw a line somewhere   \n",
       "6194                 i borrowed toms car   \n",
       "2256   you will soon be able to ski well   \n",
       "10028                     please go home   \n",
       "11671      the french like to eat snails   \n",
       "370                        ill find them   \n",
       "\n",
       "                                   predicted  \n",
       "10717             he is kind person           \n",
       "15329  toms clothes are in of fashion         \n",
       "7988             we went at a hotel a         \n",
       "1726         i dont think you with my         \n",
       "14746     we need to improve a stamps         \n",
       "6194                i bought my car           \n",
       "2256          i can see but fast well         \n",
       "10028                     go home             \n",
       "11671       your french is to a pilot         \n",
       "370                   ill pay them            "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
