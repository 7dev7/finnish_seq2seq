{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anton_Glushkov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import os.path\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEED_TRAIN = False\n",
    "NEED_TRAIN_RU = False\n",
    "\n",
    "DATASET_FILENAME = 'result.txt'\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "FILENAME = \"model.fi_ru_11_oct_19_RC1\"\n",
    "FILENAME_RU = \"model.ru_fi_28_oct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, mode='rt', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_content(content):\n",
    "    lines = content.strip().split('\\n')\n",
    "    lines = [i.split('\\t') for i in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_ru = array(parse_content(read_file(DATASET_FILENAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Mene.', 'Марш!'],\n",
       "       ['Mene.', 'Иди.'],\n",
       "       ['Mene.', 'Идите.'],\n",
       "       ...,\n",
       "       ['Tom sanoi: \"Voit suudella tyttöystävääsi hyvästiksi, jos et suutele häntä hyvästiksi\", mikä tarkoitti \"Jos et suutele tyttöystävääsi hyvästiksi, niin et näe häntä enää koskaan\".',\n",
       "        '«Можешь попрощаться со своей подружкой, если ты с ней не попрощаешься», — сказал Том, что означало «если ты не попрощаешься со своей подружкой, то больше ты её никогда не увидишь».'],\n",
       "       ['Nykypäivän maailmassa meidän täytyy varustaa kaikki lapsemme koulutuksella, joka valmistelee heidän menestykseen, riippumatta siitä, miltä he näyttävät, kuinka paljon heidän vanhempansa tienaavat tai millä postinumeroalueella he asuvat.',\n",
       "        'В современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.'],\n",
       "       ['Tällä hetkellä kun taloutemme on kasvussa, yrityksemme luovat työpaikkoja nopeimpaan tahtiin sitten 1990-luvun ja palkat ovat taas lähdössä nousuun, meidän täytyy tehdä valintoja siitä, millainen maa me haluamme olla.',\n",
       "        'В тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.']],\n",
       "      dtype='<U236')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(dataset):\n",
    "    dataset[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in dataset[:,0]]\n",
    "    dataset[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in dataset[:,1]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_lower_case(dataset):\n",
    "    for i in range(len(dataset)): \n",
    "        dataset[i,0] = dataset[i,0].lower() \n",
    "        dataset[i,1] = dataset[i,1].lower()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(dataset):\n",
    "    without_punctuations = remove_punctuations(dataset)\n",
    "    return to_lower_case(without_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['mene', 'марш'],\n",
       "       ['mene', 'иди'],\n",
       "       ['mene', 'идите'],\n",
       "       ...,\n",
       "       ['tom sanoi voit suudella tyttöystävääsi hyvästiksi jos et suutele häntä hyvästiksi mikä tarkoitti jos et suutele tyttöystävääsi hyvästiksi niin et näe häntä enää koskaan',\n",
       "        '«можешь попрощаться со своей подружкой если ты с ней не попрощаешься» — сказал том что означало «если ты не попрощаешься со своей подружкой то больше ты её никогда не увидишь»'],\n",
       "       ['nykypäivän maailmassa meidän täytyy varustaa kaikki lapsemme koulutuksella joka valmistelee heidän menestykseen riippumatta siitä miltä he näyttävät kuinka paljon heidän vanhempansa tienaavat tai millä postinumeroalueella he asuvat',\n",
       "        'в современном мире перед нами стоит задача дать всем нашим детям такое образование которое настроит их на успех вне зависимости от того как они выглядят сколько зарабатывают их родители или какой у них почтовый индекс'],\n",
       "       ['tällä hetkellä kun taloutemme on kasvussa yrityksemme luovat työpaikkoja nopeimpaan tahtiin sitten 1990luvun ja palkat ovat taas lähdössä nousuun meidän täytyy tehdä valintoja siitä millainen maa me haluamme olla',\n",
       "        'в тот момент когда наша экономика растёт наши предприятия создают рабочие места наибольшими темпами начиная с 90х годов а зарплаты снова начинают расти мы должны принять ряд решений относительно того какой страной мы хотим быть']],\n",
       "      dtype='<U236')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_fi_ru = pre_process(fi_ru)\n",
    "processed_fi_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['марш', 'иди', 'идите', ...,\n",
       "       '«можешь попрощаться со своей подружкой если ты с ней не попрощаешься» — сказал том что означало «если ты не попрощаешься со своей подружкой то больше ты её никогда не увидишь»',\n",
       "       'в современном мире перед нами стоит задача дать всем нашим детям такое образование которое настроит их на успех вне зависимости от того как они выглядят сколько зарабатывают их родители или какой у них почтовый индекс',\n",
       "       'в тот момент когда наша экономика растёт наши предприятия создают рабочие места наибольшими темпами начиная с 90х годов а зарплаты снова начинают расти мы должны принять ряд решений относительно того какой страной мы хотим быть'],\n",
       "      dtype='<U236')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_sentences = processed_fi_ru[:,1]\n",
    "ru_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mene', 'mene', 'mene', ...,\n",
       "       'tom sanoi voit suudella tyttöystävääsi hyvästiksi jos et suutele häntä hyvästiksi mikä tarkoitti jos et suutele tyttöystävääsi hyvästiksi niin et näe häntä enää koskaan',\n",
       "       'nykypäivän maailmassa meidän täytyy varustaa kaikki lapsemme koulutuksella joka valmistelee heidän menestykseen riippumatta siitä miltä he näyttävät kuinka paljon heidän vanhempansa tienaavat tai millä postinumeroalueella he asuvat',\n",
       "       'tällä hetkellä kun taloutemme on kasvussa yrityksemme luovat työpaikkoja nopeimpaan tahtiin sitten 1990luvun ja palkat ovat taas lähdössä nousuun meidän täytyy tehdä valintoja siitä millainen maa me haluamme olla'],\n",
       "      dtype='<U236')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_sentences = processed_fi_ru[:,0]\n",
    "fi_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the lists with sentence lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(sentence):\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b6cf923550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ru_l = [len(get_words(i)) for i in ru_sentences]\n",
    "fi_l = [len(get_words(i)) for i in fi_sentences]\n",
    "        \n",
    "length_df = pd.DataFrame({'ru':ru_l, 'fi':fi_l}) \n",
    "length_df.hist(bins = 30) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenization(lines): \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_tokenizer = tokenization(ru_sentences)\n",
    "ru_vocab_size = len(ru_tokenizer.word_index) + 1\n",
    "ru_length = max(ru_l)\n",
    "ru_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_tokenizer = tokenization(fi_sentences)\n",
    "fi_vocab_size = len(fi_tokenizer.word_index) + 1\n",
    "fi_length = max(fi_l)\n",
    "fi_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):          \n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)      \n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')        \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FI - RU Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encode_sequences(fi_tokenizer, fi_length, processed_fi_ru[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encode_sequences(ru_tokenizer, ru_length, processed_fi_ru[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build FI - RU LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, n):   \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, n, input_length=in_timesteps,mask_zero=True))\n",
    "    model.add(LSTM(n))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(n, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing fi model\n",
      "WARNING:tensorflow:From C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Anton_Glushkov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FILENAME):\n",
    "    print('loading existing fi model')\n",
    "    model = load_model(FILENAME)\n",
    "else:\n",
    "    model = build_model(fi_vocab_size, ru_vocab_size, fi_length, ru_length, 512)\n",
    "\n",
    "    rms = optimizers.RMSprop(lr=0.001) \n",
    "    model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NEED_TRAIN:\n",
    "    checkpoint = ModelCheckpoint(FILENAME, monitor='val_loss',  \n",
    "                             verbose=1, save_best_only=True, \n",
    "                             mode='min')\n",
    "    \n",
    "    history = model.fit(x, y.reshape(y.shape[0], y.shape[1], 1), \n",
    "                    epochs=EPOCHS, batch_size=512, validation_split = 0.2, \n",
    "                    callbacks=[checkpoint], verbose=1)\n",
    "    \n",
    "    print(history)\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.legend(['train','validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RU - FI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ru = encode_sequences(ru_tokenizer, ru_length, processed_fi_ru[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ru = encode_sequences(fi_tokenizer, fi_length, processed_fi_ru[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RU - FI LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing ru model\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FILENAME_RU):\n",
    "    print('loading existing ru model')\n",
    "    model_ru = load_model(FILENAME_RU)\n",
    "else:\n",
    "    model_ru = build_model(ru_vocab_size, fi_vocab_size, ru_length, fi_length, 512)\n",
    "\n",
    "    rms = optimizers.RMSprop(lr=0.001) \n",
    "    model_ru.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NEED_TRAIN_RU:\n",
    "    checkpoint_ru = ModelCheckpoint(FILENAME_RU, monitor='val_loss',  \n",
    "                             verbose=1, save_best_only=True, \n",
    "                             mode='min')\n",
    "    \n",
    "    history = model_ru.fit(x_ru, y_ru.reshape(y_ru.shape[0], y_ru.shape[1], 1), \n",
    "                    epochs=EPOCHS, batch_size=512, validation_split = 0.2, \n",
    "                    callbacks=[checkpoint_ru], verbose=1)\n",
    "    \n",
    "    print(history)\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.legend(['train','validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):  \n",
    "    for word, index in tokenizer.word_index.items():                       \n",
    "        if index == n: \n",
    "            return word \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_tran(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    return sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(sentence, source_tokenizer, source_len, target_tokenizer, mdl):\n",
    "    sentence = pre_tran(sentence)\n",
    "    source = encode_sequences(source_tokenizer, source_len, array([sentence]))\n",
    "    p = mdl.predict_classes(source)[0]\n",
    "    temp = []\n",
    "    for j in range(len(p)):             \n",
    "        t = get_word(p[j], target_tokenizer)\n",
    "        if j > 0:                 \n",
    "            if (t == get_word(p[j-1], target_tokenizer)) or (t == None):                       \n",
    "                 temp.append('')\n",
    "            else:\n",
    "                 temp.append(t)\n",
    "        else:       \n",
    "            if(t == None):                             \n",
    "                 temp.append('')\n",
    "            else:\n",
    "                 temp.append(t)\n",
    "    return ' '.join(temp).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_fi_ru(sentence):\n",
    "    return predict(sentence, fi_tokenizer, fi_length, ru_tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_ru_fi(sentence):\n",
    "    return predict(sentence, ru_tokenizer, ru_length, fi_tokenizer, model_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(phrases, translator):\n",
    "    for phrase in phrases:\n",
    "        print('Исходное выражение: [', phrase, ']\\nПеревод: [', translator(phrase), ']\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def double_translate(phrases, in_translator, out_translator):\n",
    "    for phrase in phrases:\n",
    "        intermediate_translate = in_translator(phrase)\n",
    "        print('Исходное выражение: [', phrase, ']\\nПромежуточный перевод: [', intermediate_translate, ']\\nИтоговый перевод: [', out_translator(intermediate_translate), ']\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное выражение: [ Думаю, Том тебя боится ]\n",
      "Перевод: [ luulen että tom on sinua ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Давай не будем тратить время на споры ]\n",
      "Перевод: [ ei tuhlata aikaa riitelyyn ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ привет ]\n",
      "Перевод: [ terve ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Я уверен, что мой сын невиновен. ]\n",
      "Перевод: [ olen varma että  on ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Я бы хотел поблагодарить тебя за то, что ты пришёл сегодня. ]\n",
      "Перевод: [ haluaisin että olisit  mukaamme ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ru_phrases = [\n",
    "    'Думаю, Том тебя боится',\n",
    "    'Давай не будем тратить время на споры',\n",
    "    'привет',\n",
    "    'Я уверен, что мой сын невиновен.',\n",
    "    'Я бы хотел поблагодарить тебя за то, что ты пришёл сегодня.'\n",
    "]\n",
    "translate(ru_phrases, translate_ru_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное выражение: [ Terve. ]\n",
      "Перевод: [ здравствуйте ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Se ei ole kovin viisasta. ]\n",
      "Перевод: [ это не очень ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Kerroin Tomille, että en tekisi sitä. ]\n",
      "Перевод: [ я говорил тому что не буду этого делать ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Minulla on sinulle yksi liiketoimintaan liittyvä ehdotus. ]\n",
      "Перевод: [ у меня есть вам тебе несколько ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Miten vietät yleensä viikonloppusi? ]\n",
      "Перевод: [ как вы  пробудете ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fi_phrases = [\n",
    "    'Terve.',\n",
    "    'Se ei ole kovin viisasta.',\n",
    "    'Kerroin Tomille, että en tekisi sitä.',\n",
    "    'Minulla on sinulle yksi liiketoimintaan liittyvä ehdotus.',\n",
    "    'Miten vietät yleensä viikonloppusi?'\n",
    "]\n",
    "translate(fi_phrases, translate_fi_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное выражение: [ Думаю, Том тебя боится ]\n",
      "Промежуточный перевод: [ luulen että tom on sinua ]\n",
      "Итоговый перевод: [ думаю  том ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Давай не будем тратить время на споры ]\n",
      "Промежуточный перевод: [ ei tuhlata aikaa riitelyyn ]\n",
      "Итоговый перевод: [ не   тратить  собой споры ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ привет ]\n",
      "Промежуточный перевод: [ terve ]\n",
      "Итоговый перевод: [ здравствуйте ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Я уверен, что мой сын невиновен. ]\n",
      "Промежуточный перевод: [ olen varma että  on ]\n",
      "Итоговый перевод: [ я уверен что ]\n",
      "\n",
      "\n",
      "Исходное выражение: [ Я бы хотел поблагодарить тебя за то, что ты пришёл сегодня. ]\n",
      "Промежуточный перевод: [ haluaisin että olisit  mukaamme ]\n",
      "Итоговый перевод: [ я бы  чтобы ты  бы ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "double_translate(ru_phrases, translate_ru_fi, translate_fi_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
